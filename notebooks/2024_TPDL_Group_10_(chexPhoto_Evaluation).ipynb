{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"76ab8bde33b542afb6d0413ffc6bb1f8","deepnote_cell_type":"markdown","id":"P7Wnon2hSjX4"},"source":["# 50.039 Theory and Practice of Deep Learning Project 2024"]},{"cell_type":"markdown","metadata":{"cell_id":"a4e06d30136d405fafb20a665bef99ba","deepnote_cell_type":"markdown","id":"8pDddTCFTJ5e"},"source":["Group 10\n","- Issac Jose Ignatius (1004999)\n","- Mahima Sharma (1006106)\n","- Dian Maisara (1006377)\n"]},{"cell_type":"markdown","metadata":{"cell_id":"abba0498fc274b1dadd617faa0fd896d","deepnote_cell_type":"markdown","id":"vca9P0PG41JP"},"source":["### Import all relevant libraries"]},{"cell_type":"code","execution_count":2,"metadata":{"cell_id":"443bbd1b51054c4b92c17f7c455a9cbb","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6500,"execution_start":1711475524785,"id":"zhwXTMVh444O","outputId":"80c0b9fe-6f28-46b3-9f07-18b3fa99035d","source_hash":null},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n","Collecting torcheval\n","  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n","Requirement already satisfied: typing-extensions in c:\\users\\user\\desktop\\50.039 tpdl\\env\\lib\\site-packages (from torcheval) (4.8.0)\n","Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n","   ---------------------------------------- 0.0/179.2 kB ? eta -:--:--\n","   ------------- -------------------------- 61.4/179.2 kB 1.7 MB/s eta 0:00:01\n","   --------------------------- ------------ 122.9/179.2 kB 1.8 MB/s eta 0:00:01\n","   ---------------------------------------- 179.2/179.2 kB 1.8 MB/s eta 0:00:00\n","Installing collected packages: torcheval\n","Successfully installed torcheval-0.0.7\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["# Matplotlib\n","# import matplotlib.pyplot as plt\n","# from matplotlib.lines import Line2D\n","# Numpy\n","import numpy as np\n","# Pandas\n","import pandas as pd\n","# Torch\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchvision.transforms import ToTensor\n","from torchvision.io import read_image\n","# TorchMetrics\n","from torchmetrics.classification import BinaryAccuracy"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0])\n","tensor([0])\n","tensor([1])\n","tensor([2])\n"]}],"source":["print(torch.argmax(torch.tensor([[0,0,0]]), dim=1))\n","print(torch.argmax(torch.tensor([[1,0,0]]), dim=1))\n","print(torch.argmax(torch.tensor([[0,1,0]]), dim=1))\n","print(torch.argmax(torch.tensor([[0,0,1]]), dim=1))"]},{"cell_type":"markdown","metadata":{"cell_id":"47e025e5145149c8ae1cf2e44cafb7ce","deepnote_cell_type":"markdown","id":"dYA9XwWzT1eq"},"source":["## Motivation"]},{"cell_type":"markdown","metadata":{"cell_id":"99112ef0090e42838c2c20296a402afa","deepnote_cell_type":"markdown","id":"Jym9IzWeTp_t"},"source":["Chest radiography is an essential diagnostic tool used in medical imaging to visualise structures and organs within the chest cavity. It is crucial for diagnosing various respiratory and heart-related conditions. However, with the increased demand for radiological reports within shorter timeframes to detect and treat illnesses, there have been insufficient radiologists available to perform such tasks at scale. Therefore, automated chest radiograph interpretation could provide substantial benefits supporting large-scale screening and population health initiatives. Deep-learning algorithms can be used to bridge this gap. They have been used for image classification, anomaly detection, organ segmentation, and disease progression prediction.\n","<br><br>\n","\n","*In this project, we aim to train a deep neural network to perform multi-label image classification on a wide array of chest radiograph images that exhibit various pathologies.*<br><br>\n","\n","\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"cell_id":"de19c43817134aa585a2812af88a3944","deepnote_cell_type":"markdown","id":"Z12EVXOwUKsx"},"source":["## Data Exploration"]},{"cell_type":"markdown","metadata":{"cell_id":"6708413788da4cf99258ee610025a356","deepnote_cell_type":"markdown","id":"Zr9mlGP5UNb_"},"source":["The training and validation datasets are from the **CheXphoto dataset** (Philips et al., 2020). <br><br> CheXphoto comprises a training set of natural photos and synthetic transformations of 10,507 X-ray images from 3,000 unique patients (32,521 data points) sampled at random from the CheXpert training dataset and an accompanying validation set of natural and synthetic transformations applied to all 234 X-ray images from 200 patients with an additional 200 cell phone photos of x-ray films from another 200 unique patients (952 data points)."]},{"cell_type":"markdown","metadata":{"cell_id":"5863ff63682e4999a8c3f4132605b5c4","deepnote_cell_type":"markdown","id":"4t_Fw1lG_ouA"},"source":["### DONT DELETE!!! Retrieving dataset from Google Cloud Storage (GCS)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"8f1186990a874ba2ac5b969bba488d06","colab":{"base_uri":"https://localhost:8080/"},"deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":278,"execution_start":1711133776362,"id":"7VPAB3GgF5n3","outputId":"25ef1be2-c583-4cd2-d89f-4f1709c50179","source_hash":null},"outputs":[],"source":["#OLD CODE : not in use as we are bringing in training datasets from notebook 1\n","# Connect to GCS to access data\n","#from google.colab import auth\n","#auth.authenticate_user() # TODO: everyone to send me gmail so I can have you authed for bucket access\n","\n","#project_id = 'tpdl-414711'\n","#bucket_name = 'chexphoto-v1'\n","#!gcloud config set project {project_id}\n","\n","# Install Cloud Storage FUSE.\n","#!echo \"deb https://packages.cloud.google.com/apt gcsfuse-`lsb_release -c -s` main\" | sudo tee /etc/apt/sources.list.d/gcsfuse.list\n","#!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n","#!apt -qq update && apt -qq install gcsfuse\n","\n","# Mount a Cloud Storage bucket or location, without the gs:// prefix.\n","#mount_path = \"chexphoto-v1\"  # or a location like \"my-bucket/path/to/mount\"\n","#local_path = f\"/mnt/gs/{mount_path}\"\n","\n","#!mkdir -p {local_path}\n","#!gcsfuse --implicit-dirs {mount_path} {local_path}"]},{"cell_type":"markdown","metadata":{"cell_id":"5e3966f4e82140bdac6364c5577dba47","deepnote_cell_type":"markdown","id":"5UoygSwiKB48"},"source":["### Loading dataset (image and labels)"]},{"cell_type":"markdown","metadata":{"cell_id":"4b6934153d044473a70920679e3b553b","deepnote_cell_type":"markdown","id":"V_IGOXZVZE3K"},"source":["### If we need to do anything to the images (greymap conversion etc.), do it here (remove if N/A)"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"df20610390874cfb90cf07797eac1cca","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":41,"execution_start":1711083237391,"source_hash":null},"outputs":[{"ename":"NameError","evalue":"name 'train_df3' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn [15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create train, test and valid datasets using CheXDataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# labels = [LOCAL_PATH +\"/train.csv\", LOCAL_PATH +\"/test.csv\", LOCAL_PATH +\"/valid.csv\"]\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m cheX_train_data \u001b[38;5;241m=\u001b[39m CheXDataset(\u001b[43mtrain_df3\u001b[49m) \u001b[38;5;66;03m#CheXDataset(labels[0])\u001b[39;00m\n\u001b[1;32m      4\u001b[0m cheX_test_data \u001b[38;5;241m=\u001b[39m CheXDataset(test_df3) \u001b[38;5;66;03m#CheXDataset(labels[1])\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cheX_valid_data \u001b[38;5;241m=\u001b[39m CheXDataset(valid_df3)\n","\u001b[0;31mNameError\u001b[0m: name 'train_df3' is not defined"]}],"source":["# Create train, test and valid datasets using CheXDataset\n","# labels = [LOCAL_PATH +\"/train.csv\", LOCAL_PATH +\"/test.csv\", LOCAL_PATH +\"/valid.csv\"]\n","cheX_train_data = CheXDataset(train_df3) #CheXDataset(labels[0])\n","cheX_valid_data = CheXDataset(valid_df3) #CheXDataset(labels[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"eea51b5eb82742f3a328fe49feab21e5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"source_hash":null},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"c273cf4e9a9e48f7b8fd38adaa818c98","deepnote_cell_type":"markdown","id":"HgoKCekkUx12"},"source":["## Model Tuning"]},{"cell_type":"markdown","metadata":{"cell_id":"31b146c0d9264786b18179542131665b","deepnote_cell_type":"markdown","id":"QQwIQXo-X989"},"source":["### First iteration - Simple feedforward neural network"]},{"cell_type":"markdown","metadata":{"cell_id":"209c03519363493f99de3f954fe32abe","deepnote_cell_type":"markdown","id":"L9EUOt_1Z3Q2"},"source":["Maybe add a description here how the multi-head was implemented (with sources)"]},{"cell_type":"markdown","metadata":{"cell_id":"7b049a3b3fa44c63aa4a58f7a1998f1a","deepnote_cell_type":"markdown","id":"wX3UD3CeYPqp"},"source":["#### Model\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"d0ba44dd9c6a4c7cb163451556057152","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"id":"c32N2YoBX6V0","source_hash":null},"outputs":[],"source":["# Write out our base model here"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"c8ff85cb6194420ea8528d507156cf8d","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"id":"gjotcljqYV-k","source_hash":null},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"ab81a118e4994f338baf4efd3bb6ed79","deepnote_cell_type":"markdown","id":"h4dzJx1DYZFc"},"source":["#### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"838876c97888421caa86711eaad342a5","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"id":"RPorquhbYbkD","source_hash":null},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"81cd3b7ce34d455c8471c9f572c1d494","deepnote_cell_type":"markdown","id":"VLTx5JIrZ8gX"},"source":["Gradually, we moved the model into a traditional CNN-based architecture to see if we can surpass the performance from above. Briefly discuss what we needed to add to the model (filtering, convolution blablabla)"]},{"cell_type":"markdown","metadata":{"cell_id":"e628f7a041c3412da4f737120a53b803","deepnote_cell_type":"markdown","id":"dyJAs1zJYiRw"},"source":["#### Model"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"10a40549d65d41338d83ac21440d778a","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"id":"8V4Db-KUYheY","source_hash":null},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"28fa1bd52f6a4d1f94a252ecf5b9a4e7","deepnote_cell_type":"markdown","id":"PWdhkE_QYm5q"},"source":["#### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"39a4683d62cf453a824638c08311af29","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"id":"xL8uRUdjYpC6","source_hash":null},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"afd1fe4fadb548a3bb07e2481c8861d2","deepnote_cell_type":"markdown","id":"ehxyUaqDYpU5"},"source":["#### Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"ace02b86307743128b4c8b618bbd16f3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"id":"yfEFs67rYrwb","source_hash":null},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"cell_id":"19d80787d418467a8828ff94da6dd8f3","deepnote_cell_type":"markdown","id":"iI5olU_kZFMt"},"source":["## Observations"]},{"cell_type":"markdown","metadata":{"cell_id":"89a1f951eb5a49a5b03857d00a668997","deepnote_cell_type":"markdown","id":"cWoXsxGDZSzV"},"source":["**TODO** Discuss whether its right for us to pluck all our evaluation and training together and discuss it here or break up the code without any descriptions\n"]},{"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d056a7b8-1929-4f43-a228-a643b0e765c5' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"deepnote_execution_queue":[],"deepnote_notebook_id":"89c05e867478484fbace446920d90168","deepnote_persisted_session":{"createdAt":"2024-03-27T01:17:26.807Z"},"kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
